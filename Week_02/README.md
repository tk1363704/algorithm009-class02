学习笔记
===============

## 1. 学习总结
本周学习了哈希表、二叉树、二叉搜索树、二叉堆、图等各种高级数据结构。
其中大部分数据结构都是早已熟悉的结构，但是对于二叉堆，本人不是很熟悉。
经过覃超老师的课程，我学习到了，二叉堆是一种特殊的二叉树, 它总是保证一棵树的最小元素(最小堆)或者最大元素(最大堆)处于树根上, 常见的应用场景就是用于构建优先队列。即最大堆是指父节点键值总是大于或等于任何一个子节点的键值。而最小堆恰恰相反，指的是父节点键值总是小于任何一个子节点的键值。
对于二叉堆，在插入节点后，需要做节点的上浮。删除堆顶节点后，首先将最后一个节点补到堆顶，再做节点的下沉。而对于建立二叉堆，也就是把一个无序的完全二叉树调整为二叉堆，本质上就是让所有非叶子节点依次下沉。

## 2. 理解HashMap
HashMap是基于哈希表实现的Map接口实现类。这个实现提供所有的map相关的操作，允许使用null的键和null的值。（HashMap与Hashtable大致是一样的，只是HashMap是不同步的，且它允许你null的键和值。）；另外，HashMap内部元素排列是无序的。

假设哈希函数能将元素合理地分散在各个哈希桶中，那么HashMap的put、get等基础操作的效率会很高（时间复杂度是常数级别O(n)）。HashMap的迭代所有元素的时间与它的实例的容量（哈希桶的数量）及大小（键值对的数量）之和成正比。因此，如果你很在意HashMap的迭代性能，就不应该初始容量设置得很高，或者把负载因子设置得很低。

一个HashMap的实例有两个参数会影响到它的性能：初始容量和负载因子。容量是指哈希表中桶的数量，初始容量就是哈希表创建时指定的初始大小。负载因子是一个度量，用来衡量当哈希表的容量满到什么程度时，哈希表就应该自动扩容。到哈希表中元素的数量超过负载因子和当前容量的乘积时，哈希表会重新计算哈希（rehashed）（即重建内部数据结构），哈希表桶的数量大约会变成原来的两倍。

一般来说，默认把负载因子值设置成0.75，在时间成本和空间成本之间是比较好的权衡。该值再高一点能减少空间开销，但会增加查找成本（表现在HashMap类的大多数操作中，包括get和put）。所以我们在设置初始化容量时，应该合理考虑预期装载的元素数量以及负载因子，从而减少rehash的操作次数。如果初始容量大于最大条目数除以加载因子（initial capacity > max entries / load factor），则不会发生重新加载操作。

如果HashMap的实例需要存储很多元素（键值对），创建HashMap时指定足够大的容量可以令它的存储效率比自动扩容高很多。

请注意如果很多的键使用的hashCode()方法结果都相同，那么哈希表的性能会很慢。为了改善影响，当键是Comparable时，HashMap会用这些键的排序来提升效率。

请注意，HashMap是不同步的。如果多条线程同时访问一个HashMap，且至少有一条线程发生了结构性改动，那么它必须在外部进行同步。（结构性改动是指任何增加或删除键值对的操作，在源码中具体体现是导致modCount属性改动的操作，仅仅修改一个键对应的值则不属于结构性改动）。外部同步通常通过同步一个封装了这个map的对象完成。

如果没有这样的对象，那么可以使用Collections.synchronizedMap把一个map转换成同步的map，这个动作最好在创建的时候完成，避免在转换前意外访问到不同步的map。

```
Map m = Collections.synchronizedMap(new HashMap(...));
```

HashMap的迭代器所有集合相关的方法都是快速失败的（fail-fast）：如果创建迭代器后，除了迭代器自身的remove方法之外，map发生了结构性改动，迭代器会抛出ConcurrentModificationException。因此，面对并发的修改，迭代吗快速、干净利落地失败，而不会冒任何风险。

请注意，迭代器快速失败的特性在不同步的并发修改时，是不能作出硬性保证的。快速失败的迭代器会尽最大努力抛出ConcurrentModificationException。因此，编写依赖于此异常的程序以确保其正确性是错误的：迭代器的快速失败行为应该仅用于检测错误。
